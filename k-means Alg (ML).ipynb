{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13b23f22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 382)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<tokenize>:382\u001b[1;36m\u001b[0m\n\u001b[1;33m    for index in range(no_of_clusters):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# Importing needed packages and libraries for program \n",
    "\n",
    "import random \n",
    "\n",
    "import math \n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import sys \n",
    "\n",
    "from scipy.ndimage import rotate \n",
    "\n",
    " \n",
    "# k_means_uwplatt_init() function used to initialize extended matrix and  \n",
    "\n",
    "# centroids based on given number of clusters. Designed by Caleb Moore. \n",
    "\n",
    "def k_means_uwplatt_init(no_of_clusters, data_matrix): \n",
    "\n",
    "    centroid_matrix = np.zeros((no_of_clusters, 2)) \n",
    "\n",
    " \n",
    "\n",
    "    # Need to initialize the first no_of_clusters cluster centroids –  \n",
    "\n",
    "    # in this case, random sampling from the entire data_matrix \n",
    "\n",
    "    for x in range (0, no_of_clusters): \n",
    "\n",
    "        #generate a random index to grab centroid from the range of indexes \n",
    "\n",
    "        index = random.randint(0, len(data_matrix) - 1)  \n",
    "\n",
    "        centroid_matrix[x] = data_matrix[index] \n",
    "\n",
    "     \n",
    "\n",
    "    #copy centroid_matrix to centroid_matrix_prev  \n",
    "\n",
    "    centroid_matrix_prev = np.copy(centroid_matrix)  \n",
    "\n",
    " \n",
    "\n",
    "    extended_matrix = np.zeros((len(data_matrix), no_of_clusters + 3)) \n",
    " \n",
    "\n",
    "    for x in range (0, len(data_matrix)): \n",
    "\n",
    "        extended_matrix[: ,0] = data_matrix[:,0] \n",
    "\n",
    "        extended_matrix[:, 1] = data_matrix[:,1] \n",
    "\n",
    " \n",
    "\n",
    "    return extended_matrix, centroid_matrix, centroid_matrix_prev \n",
    "\n",
    "     \n",
    "\n",
    "# k_means_uwplatt_assignment() function used to assign each matrix to one of \n",
    "\n",
    "# the centroids created. Co-written by Dayton Ellis, Jarrod Flanders and Caleb Moore. \n",
    "\n",
    "def k_means_uwplatt_assignment(extended_matrix, centroid_matrix): \n",
    "\n",
    "     \n",
    "\n",
    "    # Checking the distance of every datapoint for each centroid. \n",
    "\n",
    "    for index in range(len(centroid_matrix)): \n",
    "\n",
    "        xvar = [0] * len(extended_matrix) \n",
    "\n",
    "        yvar = [0] * len(extended_matrix) \n",
    "\n",
    "         \n",
    "\n",
    "        xvar = centroid_matrix[index][0] - extended_matrix[:,0] \n",
    "\n",
    "        yvar = centroid_matrix[index][1] - extended_matrix[:,1] \n",
    "\n",
    "          \n",
    "\n",
    "        # Putting squared distance between each data point and centroid into \n",
    "\n",
    "        # extended matrix. \n",
    "\n",
    "        extended_matrix[:,(2 + index)] = (xvar[:] ** 2) + (yvar[:] ** 2) \n",
    "\n",
    " \n",
    "    # Extracting data points distances from cluster centroids and finding          # the smallest distance \n",
    "\n",
    "    subset = extended_matrix[ :, 2: 3 + centroid_matrix.shape[0] - 1] \n",
    "\n",
    "    np.set_printoptions(threshold=sys.maxsize)  \n",
    "\n",
    " \n",
    "\n",
    "    # Returning the cluster with the smallest distance as the label for each              # data point \n",
    "\n",
    "    extended_matrix[:, extended_matrix.shape[1] - 1] = np.argmin(subset, axis = 1) \n",
    "\n",
    "    test = np.argmin(subset, axis = 1) \n",
    "\n",
    "     \n",
    "\n",
    "    return extended_matrix \n",
    "\n",
    " \n",
    "# k_means_uwplatt_plot_clusters() function designed to \n",
    "\n",
    "def k_means_uwplatt_plot_clusters(extended_matrix, centroid_matrix): \n",
    "\n",
    "    cluster_colors = ['r', 'g', 'b', 'y', 'black', 'purple'] \n",
    "\n",
    "         \n",
    "\n",
    "    for cluster_index in range(0, len(centroid_matrix)): \n",
    "\n",
    "    # Create a list of all points belonging to cluster_index \n",
    "\n",
    "        cluster_data_points = extended_matrix[extended_matrix[:, extended_matrix.shape[1] - 1] == cluster_index] \n",
    "\n",
    "        plt.scatter(cluster_data_points[:, 0], cluster_data_points[:, 1], color = cluster_colors[cluster_index], s = 2) \n",
    "\n",
    "         \n",
    "\n",
    "    for index in range(0, len(centroid_matrix)): \n",
    "\n",
    "        plt.scatter(centroid_matrix[index][0], centroid_matrix[index][1], marker = \"D\", color = cluster_colors[index], edgecolors = \"Black\") \n",
    "\n",
    "    plt.show() \n",
    "\n",
    " \n",
    "# k_means_uwplatt_copy_centroids() function is designed to simply copy the current centroid \n",
    "\n",
    "# matrix into the previous centroid matrix, and return said matrix.  \n",
    "\n",
    "# Designed by Dayton Ellis \n",
    "\n",
    "def k_means_uwplatt_copy_centroids(centroid_matrix, centroid_matrix_prev): \n",
    "\n",
    "    centroid_matrix_prev = np.copy(centroid_matrix) \n",
    "\n",
    "    return centroid_matrix_prev \n",
    "\n",
    " \n",
    "# k_means_uwplatt_update() function is used to update the current centroid matrix based on the values of the clusters’ current datapoints.  \n",
    "\n",
    "# Designed by  \n",
    "\n",
    "def k_means_uwplatt_update(extended_matrix, centroid_matrix): \n",
    "\n",
    "    print(centroid_matrix) \n",
    "\n",
    "    print(\"break\") \n",
    "\n",
    "     \n",
    "\n",
    "    for cluster_index in range(0, len(centroid_matrix)): \n",
    "\n",
    "         \n",
    "\n",
    "        # Create a list of all points belonging to cluster_index \n",
    "\n",
    "        cluster_data_points = extended_matrix[extended_matrix[:, extended_matrix.shape[1] - 1] == cluster_index] \n",
    "\n",
    "         \n",
    "\n",
    "        # Checks to make sure that there is at least one data point in the \n",
    "\n",
    "        # cluster \n",
    "\n",
    "        if(len(cluster_data_points) == 0): \n",
    "\n",
    "            continue \n",
    "\n",
    " \n",
    "\n",
    "        # Update the x and y coordinates of the centroid to match the mean x  \n",
    "\n",
    "        # and y coordinates of the cluster \n",
    "\n",
    "        centroid_matrix[cluster_index][0] = np.sum(cluster_data_points[:, 0]) / cluster_data_points.shape[0] \n",
    "\n",
    "        centroid_matrix[cluster_index][1] = np.sum(cluster_data_points[:, 1]) / cluster_data_points.shape[0] \n",
    "\n",
    "    print(centroid_matrix) \n",
    "\n",
    "    return centroid_matrix \n",
    " \n",
    "\n",
    "# k_means_uwplatt_test_convergence() function is designed to check the distance between the current centroids and their previous versions to determine if further cycles are necessary. \n",
    "\n",
    "# Designed by Dayton Ellis \n",
    "\n",
    "def k_means_uwplatt_test_convergence(centroid_matrix, centroid_matrix_prev): \n",
    "\n",
    "    # Returns a 1 to signify the centroids have converged \n",
    "\n",
    "    isConverged = 1 \n",
    "\n",
    " \n",
    "\n",
    "    # Similar method of checking distance as between centroids and data sets. \n",
    "\n",
    "    for index in range(len(centroid_matrix)): \n",
    "\n",
    "        x = centroid_matrix[index][0] - centroid_matrix_prev[index][0] \n",
    "\n",
    "        y = centroid_matrix[index][1] - centroid_matrix_prev[index][1] \n",
    "\n",
    "        if ((x ** 2) + (y ** 2) > 0.01): \n",
    "\n",
    "           # If any centroids fail the stopping criteria, continue converging.  \n",
    "\n",
    "           isConverged = 0 \n",
    "\n",
    "     \n",
    "\n",
    "    return isConverged \n",
    "\n",
    " \n",
    "# k_means_uwplatt_test_convergence() function is designed to act as a loop, running an initialization function before cycling through the same bunch over and over to converge the centroids and display them. \n",
    "\n",
    "# Designed by Dayton Ellis and  \n",
    "\n",
    "def k_means_uwplatt(data_matrix, no_of_clusters): \n",
    "\n",
    "    isConverged = 0 \n",
    "\n",
    "    iterations = 0 \n",
    "\n",
    " \n",
    "\n",
    "    # Initializing the extended matrix and centroid matrix. \n",
    "\n",
    "    extended_matrix, centroid_matrix, centroid_matrix_prev = k_means_uwplatt_init(no_of_clusters, data_matrix) \n",
    "\n",
    " \n",
    "\n",
    "    # Looping functions to gradually converge the centroids. \n",
    "\n",
    "    while True: \n",
    "\n",
    "        extended_matrix = k_means_uwplatt_assignment(extended_matrix, centroid_matrix) \n",
    "\n",
    "        k_means_uwplatt_plot_clusters(extended_matrix, centroid_matrix) \n",
    "\n",
    "        centroid_matrix_prev = k_means_uwplatt_copy_centroids(centroid_matrix, centroid_matrix_prev) \n",
    "\n",
    "        k_means_uwplatt_update(extended_matrix, centroid_matrix) \n",
    "\n",
    "        isConverged = k_means_uwplatt_test_convergence(centroid_matrix, centroid_matrix_prev) \n",
    "\n",
    "        # Incrementing the iteration count to print out once finished. \n",
    "\n",
    "        iterations = iterations + 1 \n",
    "\n",
    "         \n",
    "\n",
    "        # Breaking while loop if isConverged is returned as true (1). \n",
    "\n",
    "        if isConverged != 0: \n",
    "\n",
    "            break \n",
    "\n",
    " \n",
    "\n",
    "    return extended_matrix, iterations \n",
    "\n",
    " \n",
    "# generate_dataset() function is designed to populate all the needed data sets to be used in the k-means algorithm based on given number of points and number of clusters. Designed by Jarrod Flanders. \n",
    "\n",
    "def generate_dataset(no_of_clusters, no_of_points_per_cluster): \n",
    " \n",
    "\n",
    "    # Creates an empty array to store the clusters \n",
    "\n",
    "    my_array = [0] * no_of_clusters \n",
    "\n",
    "    cluster_colors = ['r', 'g', 'b', 'y', 'black', 'purple'] \n",
    "\n",
    " \n",
    "\n",
    "    #Creates 2D clusters with the desired number of points per cluster \n",
    " \n",
    "\n",
    "    for index in range(no_of_clusters): \n",
    "\n",
    "        cluster = np.random.randn(no_of_points_per_cluster, 2) \n",
    "\n",
    " \n",
    "\n",
    "        # Sets the current array index to the created cluster \n",
    "\n",
    "        my_array[index] = np.array(cluster) \n",
    " \n",
    "\n",
    "    # Applys scaling, shifting, and rotations to all clusters \n",
    "\n",
    "    for index in range(no_of_clusters): \n",
    "\n",
    " \n",
    "\n",
    "        # Creates matrix for scaling \n",
    "\n",
    "        scaling_a = round(random.uniform(-2, 2), 2) \n",
    "\n",
    "        scaling_b = round(random.uniform(-2, 2), 2) \n",
    "\n",
    "        scaling_c = round(random.uniform(-2, 2), 2) \n",
    "\n",
    "        scaling_d = round(random.uniform(-2, 2), 2) \n",
    "\n",
    "        scaling = np.array([[scaling_a, scaling_b], [scaling_c, scaling_d]]) \n",
    "\n",
    " \n",
    "\n",
    "        # Stores dot product between cluster and scaled matrix \n",
    "\n",
    "        scaled_data = (my_array[index]).dot(scaling) \n",
    "\n",
    "         \n",
    "\n",
    "        # Upper bound for rotation \n",
    "\n",
    "        upper_bound = math.pi*2 \n",
    "\n",
    " \n",
    "\n",
    "        # Random value for rotating from 0 to upper bound with 5 decimal points \n",
    "\n",
    "        random_rotation = round(random.uniform(0, upper_bound), 5) \n",
    "\n",
    " \n",
    "\n",
    "        # Converts random rotation to sin and cos values \n",
    "\n",
    "        cos = math.cos(random_rotation) \n",
    "\n",
    "        sin = math.sin(random_rotation) \n",
    "\n",
    " \n",
    "\n",
    "        # Creates matrix based off random rotation value and stores the  \n",
    "\n",
    "        # dot product \n",
    "\n",
    "        rotate_matrix = np.array([[cos, -sin], [sin, cos]]) \n",
    "\n",
    "        rotated_data = scaled_data.dot(rotate_matrix.T) \n",
    " \n",
    "\n",
    "        # Random cluster shifted values \n",
    "\n",
    "        random_shift_x = round(random.uniform(-10, 10), 5) \n",
    "\n",
    "        random_shift_y = round(random.uniform(-10, 10), 5) \n",
    "\n",
    "        shift_matrix = np.array([random_shift_x, random_shift_y]) \n",
    "\n",
    " \n",
    "\n",
    "        # Shifts cluster by taking the dot product of cluster with shifted  \n",
    "\n",
    "        # matrix values \n",
    "\n",
    "        shifted_data = rotated_data.dot(rotate_matrix.T) + shift_matrix \n",
    "\n",
    " \n",
    "\n",
    "        # Stores new transfromed cluster in array of clusters \n",
    "\n",
    "        my_array[index] = np.array(shifted_data) \n",
    "\n",
    " \n",
    "\n",
    "     # Displays the clusters \n",
    "\n",
    "     for index in range(no_of_clusters): \n",
    "\n",
    "        plt.scatter(my_array[index][:, 0], my_array[index][:, 1], color = cluster_colors[index]) \n",
    "\n",
    "     plt.show() \n",
    "\n",
    " \n",
    " \n",
    "\n",
    "     # Concatenates all clusters into a single matrix and returns it \n",
    "\n",
    "     data_matrix = np.concatenate(my_array, axis = 0) \n",
    "\n",
    " \n",
    "\n",
    "     return data_matrix \n",
    "\n",
    " \n",
    "# main() function meant to simply make calls to other key functions used in the k-means clustering \n",
    "\n",
    "# algorithm. No dedicated author for this function as it came together during group sessions. \n",
    "\n",
    "def main(): \n",
    "\n",
    "    data_matrix = generate_dataset(4, 1000) \n",
    "\n",
    "    extended_matrix, iterations = k_means_uwplatt(data_matrix, 4) \n",
    "\n",
    "    print(iterations) \n",
    "\n",
    " \n",
    "# Call to main function, initiates program \n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "\n",
    "    main() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368fb218",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ca1561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea1da1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbce16a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e6cd40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
